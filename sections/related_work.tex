\section{HealthSHIELD}
\setauthor{Christoph Lasinger}
A paper published in October 2020 suggests a possible use for body tracking software, such as Animotion, in monitoring hygiene best practices during the at the time highly 
prevalent COVID-19 pandemic. In this paper a prototype system was used to recognize unconscious hand-to-face gestures that pose a potentially dangerous pathway for the virus
to enter the human body. This system called HealthSHIELD was able to correctly recognize such gestures with a 91 percent accuracy and could therefore reliably be used to warn
people in real time of its danger. This paper demonstrates that similar face and body tracking software can be used to generally correct negative unconscious, human habits
and for example improve the safety of work environments as a result. \cite{HealthSHIELD}

\section{Multisensor-fusion}
\setauthor{Christoph Lasinger}
Another paper published in 2010 a 3D full-body motion capture system was augmented with orientation data from inertial sensors in order to improve performance and stability.
As Animotion relies solely on video data rapid motions, noise or one body part covering another result in common issues, such as tracking artifacts. For example, during the
process of figuring out the limitations of Animotion a common problem that occurred was that gestures toward or away from the camera were not being accurately repeated by the
virtual model. This occurred due to the lack of depth information in video data. This paper shows that using data gathered from other sensors in combination with video data
increases performance and stability of motion capture systems and reduces some of the aforementioned issues. \cite{Multisensor-fusion}

\section{AlterEcho}
\setauthor{Christoph Lasinger}
The following paper describes a process of controlling a virtual character that differs a lot from conventional methods of head and facial motion capture or even keyboard
interfaces, i.e., playing preprogrammed animations of an avatar based on keyboard shortcuts triggered by the user. \cite{AlterEcho}

The technology introduced in the paper is called the AlterEcho VTubing animation system. The authors declare four requirements that any good VTubing animation system should
fulfil. It should function automatically, be inexpensive and adaptable, and support the differences between the real and virtual world. AlterEcho therefore aims to satisfy
these criteria by functioning in the following manner: the user, i.e., the VTuber sits in front of their computer running AlterEcho playing for example some video game. They
record themselves via some camera connected to the computer that records their head and facial movements and talk into a microphone. Based on all these inputs, the video
stream, audio stream, keyboard events, mouse events, the system calculates and renders the moving avatar that is displayed.

In addition to mirroring the movements of the user AlterEcho also simulates other human gestures that are not explicitly made. For example, the avatar performs beat gestures to
underline the rhythm of speech or slouches their shoulders when expressing indifference which is inferred by the analysed recorded audio stream. In order to make the avatar seem
natural motions such as crossing its arms or scratching its face are added from time to time as well. Finally, the user is also able to customize the avatar by making it more
introverted or extroverted and setting its energy level. All of these features result in a more natural, human-like virtual model which reduces the likelihood of it falling into
the uncanny valley.

In May 2021 the authors conducted a user study with 315 participants in regard to the performance of AlterEcho including a comparison to a popular VTubing system called VMagicMirror
and pure motion capture data. In this survey AlterEcho vastly outperformed its competitors, overall being rated the most engaging, most natural, and most preferred (defined as
“being happy with this avatar”). Although more precise feedback included that some participants prefer a less natural avatar as they see a unique charm in virtual models.
In general, the personification of the avatar was positively received.

In conclusion, AlterEcho manages to produce a virtual model that is vastly superior to Animotion largely due to taking a lot more parameters into account. It can be said that to
realistically replicate human behaviour far more than simple video data is necessary, which naturally comes with lots more issues and needed fine tuning. However, as the authors
found out when conducting their user study, perhaps an avatar that perfectly mirrors a human is not to be desired as it sometimes defeats the purpose of the avatar itself.

\section{Adaptive Background Models and Mean-Shift Analysis}
\setauthor{Christoph Lasinger}
What distinguishes the full-body motion capture systems described in this paper from others is a feature the authors call three-dimensional pose detection, which they are using
in combination with ordinary three-dimensional body tracking. It is supposed to not only help automate the body tracking system but also increase its accuracy and robustness.
Another benefit of this approach to tracking is that it is highly parallel and therefore functions well on a GPU. \cite{Adaptive-background-models}

To evaluate the performance of their method the authors decided to compare this system to the competitor Kinect, a popular and effective body tracking system developed by Microsoft.
Even though Kinect boast many other advantages, it is not able to accurately track full-body movement in case of a significant occurrence of occlusions. The system presented in
this paper intends to circumvent this flaw while still maintaining the same advantages as Kinect.

The main component of this system is a hybrid motion capture system that automatically alternates between three-dimensional pose detection and pose tracking. The pose detection
works by labelling each pixel captured by the camera and associating them with a particular bone segment using randomized decision trees. By combining these two features
they negate each other's disadvantages and generally improve the quality of body tracking. Moreover, in its initiation process the system calibrates the skeleton structure
of the user in order to create a model of bone segments. This process is only necessary once per user and makes it possible for the system to better accommodate different body
types.

Through practical tests the authors show that in comparison to other three-dimensional tracking systems the system described in this paper achieves state-of-the-art accuracy.
This success can largely be attributed to the features that separates this system from other. It can be concluded that a combination of pose tracking and detection in addition
to skeleton calibration overall improves the accuracy and robustness of full body tracking systems. Therefore, adding similar features to Animotion in the future should be
noted as an option.
