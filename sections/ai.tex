\section{What is artificial intelligence?}
\setauthor{Romeo Bhuiyan}
The concept of AI has a long history that dates back to ancient times, when people first tried to build machines that could mimic human abilities. In the modern era, the term "AI" was first coined in 1956 by computer scientist John McCarthy, who defined it as \textit{the science and engineering of making intelligent machines} \footnote{johnmcCarthy:1956}.
% \cite[the science and engineering of making intelligent machines]{johnmcCarthy:1956} .
\\
\\
Today, these machines are designed to be able to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and understanding natural language. AI can be applied to a wide range of fields, from healthcare and finance to education and transportation, with the goal of making systems more efficiently and effectively. AI can be classified into two broad categories: narrow or weak AI, which is designed to perform a specific task, and general or strong AI, which has the ability to perform any intellectual task that a human being can perform.

\section{Philosophy of artificial intelligence}
\setauthor{Christioph Lasinger}
Can a machine think? Thinking seems to be one of, if not the most important part of being human, as seen in René Descartes' first principle of philosophy “Cogito, ergo sum” (“I think, therefore I am”). So it goes to reason that, if we, as homo sapiens, were to see us superior to other animals on earth, it would be our intelligence, our conscious thinking, that would seem to differentiate us, make us special. Assuming this line of reasoning to be true, then it would only seem logical to think that we, as humans, are superior to machines in that regard as well. But what if that were to be taken away?
\\
\\
Throughout the course of history humans have practically been obsessed with self-imitation, be it wall-paintings, statues, portraits, photos, films or today's machines. The earliest example of artificial humans may be Greek gods, or rather Greek mythology as a whole, including for example architect and craftsman Daedalus, who created statues and machines that were sometimes impossible to distinguish from real human beings. Ancient Egypt also featured statues of gods behaving like humans and even though they were being controlled not by a god, but through complex mechanisms, such as quicksilver or hydraulics, or even simple puppeteering strings, the Egyptians still feared and revered them. They saw it not as blasphemy but as gods acting through guided souls, even though they might be that of a master and puppet.
\\
\\
However, not everyone would view such creations as positive as the Greeks and Egyptians. As even before their time a different culture, or to be more accurate religion had rules regarding artificial humans, the so called ten commandments, of which the second one states “You shall not make for yourself a carved image, or any likeness of anything that is in heaven above, or that is in the earth beneath, or that is in the water under the earth. You shall not bow down to them or serve them, for I the LORD your God am a jealous God ...". Of course, any religious text is open to interpretation, but it seems a rather popular one was that of Hermes Trismegistor, purported author of the Hermetica, a series of ancient texts that lay the basis of philosophical systems known as Hermetecicism, who stated that man has created statues, infused with the souls of demons and angels through holy rituals.
\\
\\
The purpose of mentioning these two views regarding artificial humans is that they are essentially the two fundamental views of the western world regarding “thinking machines”, or artificial intelligence, as well. This can be seen in statements made by both critics and proponents of AI. 

\section{The future of artificial intelligence}
\setauthor{Romeo Bhuiyan}
The future of AI is difficult to predict with certainty, but it is likely that AI will continue to advance and become increasingly integrated into our daily lives. AI has the potential to revolutionize many industries, from healthcare and transportation to education and finance. It could also have a major impact on the job market, with some jobs being automated by AI and other jobs being created to support the technology. However, it is important to consider the potential drawbacks of AI and ensure that it is developed and used ethically. Overall, the future of AI seems promising, but it is important to approach it with caution and consideration. As the future of AI is very likely to lie somewhere between a very positive one (extreme optimism) and a very negative one (extreme pessimism), it makes sense to analyze those two specifically.
\\
\\
An extremely pessimistic future of AI in the world would involve the technology being used in ways that are harmful to humanity. In this scenario, AI could be used to create weapons of mass destruction, or to control and manipulate people for nefarious purposes. It could also be used to create a surveillance state, where people's every move is monitored and tracked. Additionally, the widespread use of AI could lead to widespread job loss and economic instability, as many jobs are automated and replaced by machines. In a worst-case scenario, the development of AI could even lead to a global conflict over control of the technology.
\\
\\
An extremely optimistic future would entail an AI with highly advanced and integrated technology that is able to solve many of the world's most pressing problems. In this scenario, AI would be used to improve healthcare, reduce poverty and inequality, and address climate change. It would also be used to make transportation faster, safer, and more efficient, and to improve education by providing personalized learning experiences for students. Moreover, AI could be used to help us better understand and protect the natural world, and to explore the universe. Overall, this extremely optimistic future of AI would involve the technology being used to enhance and improve human life in countless ways.



\section{How does a neural network work?}
\setauthor{Romeo Bhuiyan}
A neural network is a type of machine learning algorithm modeled after the structure and function of a human brain (neural linking). It is composed of many interconnected processing nodes, called neurons, which work together to process information. 
\\
\\
Each neuron receives input from other neurons, processes that information, and produces an output. This output is then passed on to other neurons in the next layer of the network. In this way, information is passed through the network, from the input layer to the output layer, allowing the neural network to learn and make predictions based on the data it is given.
\\
\\
\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\textwidth]{pics/neuralnetwork.jpg}
    \caption{Complex neural network}
\end{figure}
\\
\\
\\
The specific details of how a neural network works can vary depending on its architecture and the type of problem it is being used to solve. But in general, a neural network is able to learn from data by adjusting the strength of the connections between its neurons, these connections being called weights, based on the input it receives. Over time, the network is able to improve its predictions by adjusting these weights in a way that minimizes errors between the network's output and the correct output.

\subsection{Solving methods}
There are three basic methods for solving problems: search-, knowledge-, and algorithmic methods. Every method involves searching through a space of possible solutions whilst optimizing a pre-defined evaluation function, that can lead to the following "Combinatorial explosion". The methods can range from simplex hill climbing via alpha-beta pruning techniques to knowledge "chunking". 
Example: the chess endgame of king and three pawns versus king and three pawns requires an explicit table of half a billion moves and a run-time of ten quadrillion years to evaluate all possibilities. The success of the CMU "chunker" program which uses chess domain knowledge chunks is that it reduces this run-time to about one minute.
\\
\\
\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\textwidth]{pics/combiexplo.png}
    \caption{Combinatorial explosion} 
\end{figure}

\section{How does face tracking work?}
\setauthor{Romeo Bhuiyan}
Face tracking is a technology that allows a computer or device to identify and monitor the movements of a person's face in real time. This is typically done using a combination of computer vision algorithms and specialized hardware, such as a camera or depth sensor.
\\
\\
To track a face, the system first detects the face in the video feed from the camera or depth sensor. This is typically done using a machine learning algorithm trained to recognize faces in images. Once the face has been detected, the system then uses various techniques to track the movements of the face, such as tracking the position of key facial features (such as the eyes and mouth) over time. This allows the system to accurately follow the face as it moves within the frame, even if it turns or changes orientation.
\\
\\
The resulting data can be used for a variety of purposes, such as enabling facial recognition (to identify who the person is), animating virtual characters, or controlling a user interface.
\\
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\textwidth]{pics/bhuiyanfracetracking.png}
    \caption{Face tracking experiment done by Romeo Bhuiyan}
\end{figure}


\section{How does body tracking work?}
\setauthor{Romeo Bhuiyan}
Body tracking is the process of using technology to track the movement of a person's body. This is typically done using sensors or cameras that capture the movement of the body and then use algorithms to interpret that movement and translate it into digital data that can be used for various purposes. 
\\
\\
To track a body, the algorithm first detects the presence of a body in the video or data. It then uses various techniques to identify specific features of the body, such as the limbs, torso, or other distinctive features. This allows the algorithm to track the body as it moves over time. 
\\
\\
In addition to tracking the location of the body, some algorithms can also track other features, such as body movements or gestures. This allows them to be used for a variety of applications, such as video surveillance, virtual reality, gaming, human-computer interaction, and fitness tracking.

\section{Comparison between MediaPipe and TensorFlow.js}
\setauthor{Romeo Bhuiyan}
In this case face tracking was needed in order to get a virtual model animated. The two libraries MediaPipe and TensorFlow.js were tested in python to decide which one is better suited for our purpose. It is difficult to say which approach is "better" for face, hand, and body tracking in the browser, as it will depend on the specific requirements and constraints of one's project. Both MediaPipe and TensorFlow.js are powerful tools that can be used to perform these tracking tasks, but they have different strengths and limitations.
\\
\\
MediaPipe is a library developed by Google that is specifically designed for real-time multimedia processing tasks, such as hand and face tracking. It is written in C++ with some Python bindings and can be used to build cross-platform pipelines for performing various computer vision and machine learning tasks. MediaPipe is optimized for low-latency, real-time processing and is used to build applications that run on a variety of platforms, including the browser.
\\
\\
In contrast, TensorFlow.js is a JavaScript library for training and deploying machine learning models in the browser. It is based on the TensorFlow library, a popular machine learning library developed by Google. TensorFlow.js allows you to build and train machine learning models using JavaScript, and it can be used to perform a variety of tasks, including image and text classification, time series forecasting, and natural language processing.
\\
\\
Both MediaPipe and TensorFlow.js are able to handle face and hand tracking in the browser, but they have different trade-offs and may be better suited for different types of projects. MediaPipe is optimized for real-time processing and is good for building applications that require low latency, such as augmented reality or interactive applications. However, TensorFlow.js is a general-purpose machine learning library that is suited for building machine learning models and deploying them in the browser, but it may not be as efficient for real-time processing as MediaPipe. Thinking that in the future more content will likely be added to the project, we have decided to use MediaPipe as our real-time multimedia library solution.


\section{Performance}
\setauthor{Romeo Bhuiyan}
Performance is important in the field of AI for a number of reasons. Firstly, the goal of AI is to mimic human intelligence and decision-making, for which performance is a key factor in determining how well a machine is able to do this. In order for AI to be useful and effective, it must be able to perform tasks at a level that is comparable to or better than a human.
\\
\\
Performance is also essential due to its determination of speed and efficiency of an AI system. In many cases, the ability of AI to quickly and accurately process large amounts of data and make decisions based on that data can be a key factor in its success. For example, in the field of finance, a high-performing AI system can help traders make faster, more informed decisions, which can lead to better investment returns.
\\
\\
Additionally, it can affect the cost and feasibility of implementing an AI system. If an AI system is not able to perform well, it may be too expensive or too unreliable to be used in practice. As a result, the performance of AI systems is a critical factor that must be considered in the development and deployment of these technologies.
